{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "import optuna\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import weakref\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the generator model architecture\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.read_csv(\"filtered_data_After_blanced.csv\")\n",
    "Features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ebe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a multiclass classification problem onehotencoding our Y.\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f626ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "print (x_train.shape)\n",
    "print (y_train.shape)\n",
    "print (x_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making our data compatible to model.\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input shape for 1D convolutional model\n",
    "input_shape = x_train.shape[1], 1\n",
    "\n",
    "# Build the generator model\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_shape=input_shape))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(2048))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(4096))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(256))\n",
    "generator.add(LeakyReLU(alpha=0.01))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "generator.add(Dense(1, activation='tanh'))\n",
    "\n",
    "# Plot the generator model architecture\n",
    "plot_model(generator, to_file='generator.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Build the discriminator model\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv1D(256, kernel_size=5, strides=2, input_shape=input_shape, padding=\"same\"))\n",
    "discriminator.add(LeakyReLU(alpha=0.01))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Conv1D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(LeakyReLU(alpha=0.01))\n",
    "discriminator.add(BatchNormalization(momentum=0.8))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Plot the discriminator model architecture\n",
    "plot_model(discriminator, to_file='discriminator.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Combine the generator and discriminator to create the GAN\n",
    "gan_input = Input(shape=input_shape)\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "\n",
    "# Plot the GAN model architecture\n",
    "plot_model(gan, to_file='gan.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Compile the GAN\n",
    "gan.compile(loss='categorical_crossentropy',metrics = [\"accuracy\"], optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "gan.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=5, min_lr=0.00001)\n",
    "\n",
    "history=gan.fit(x_train, y_train, batch_size=64, epochs=250 ,validation_data=(x_test, y_test), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , gan.evaluate(x_test,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(250)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(40,20)\n",
    "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
    "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
    "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()\n",
    "gan.save(\"GanModelFileH5.h5\")\n",
    "print(\"Model saved to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on test data.\n",
    "pred_test = gan.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "\n",
    "y_test = encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()\n",
    "\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b68cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d948418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
